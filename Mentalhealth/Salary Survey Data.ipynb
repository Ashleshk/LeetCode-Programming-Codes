{"cells":[{"cell_type":"markdown","id":"3b05e587-87e3-4bec-9511-ddaae6552ac4","metadata":{},"source":["![Illustration of silhouetted heads](mentalhealth.jpg)"]},{"cell_type":"markdown","id":"48bca32d","metadata":{},"source":["Fitting a linear regression model\n","An anonymous salary survey has been conducted annually since 2015 among European IT specialists. In 2018, hundreds of respondents volunteered to participate. Included in the survey data are the number of years of experience respondents had and their current salary.\n","\n","You are going to analyze the relationship between these two variables to find out if more years of experience results in higher or lower salary.\n","\n","Your independent variable is experience_years, and your dependent variable is current_salary.\n","\n","The data has been loaded for you as data, along with statsmodels.api and pandas, as sm and pd, respectively."]},{"cell_type":"code","execution_count":null,"id":"eafce891","metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["# Define variable, x and y\n","x = salary_survey.experience_years.tolist()\n","y = salary_survey.current_salary.tolist()\n","\n","# Add the constant term\n","x = sm.add_constant(x)\n","\n","# Perform .OLS() regression and fit\n","result = sm.OLS(y,x).fit()\n","\n","# Print the summary table\n","print(result.summary())"]},{"cell_type":"markdown","id":"ea1b1eb0","metadata":{},"source":["Visualizing survey data\n","Following up on the previous exercise on survey data among European IT specialists, visualize the linear relationship between experience_years and current_salary, to give a rough estimate of what different levels of experiences are earning.\n","\n","The data has been loaded for you as data, along with pandas, Matplotlib.pyplot, and NumPy, as pd, plt, and np, respectively"]},{"cell_type":"code","execution_count":null,"id":"7aa12123","metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["# Plot the original values using a scatter plot\n","x = data.experience_years.tolist()\n","y = data.current_salary.tolist()\n","plt.scatter(x,y)\n","\n","# Get the range of data\n","max_x = data.experience_years.max()\n","min_x = data.experience_years.min()\n","\n","# Get the range of values\n","x = np.arange(min_x,max_x,1)\n","y = 1590.4569 * x + 58080\n","\n","# Plot the regression line\n","plt.plot(x, y,'r')\n","plt.show()"]},{"cell_type":"markdown","id":"157e7f14","metadata":{},"source":["Are women more extroverted?\n","Susan is convinced that women are more extroverted than men, because her best friend Betsy, loves to party, and her other best friend Oliver, would rather be in his room reading books.\n","\n","To support her hypothesis, she posts a survey online, asking all of her Facebook friends to score themselves on how extroverted they think they are. One indicates a complete introvert while eight indicates a complete extrovert.\n","\n","She wants to compare the average male score from male_survey, to the average female score, female_survey, using the two-sample t-test, but must first, check out the three assumptions associated with the test.\n","\n","pandas and scipy.stats have been loaded for you as pd and stats, respectively."]},{"cell_type":"code","execution_count":null,"id":"006140ad","metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["# Calculate mean extroversion of males \n","male_mean = male_survey.extroversion.mean()\n","\n","# Calculate mean extroversion of females \n","female_mean = female_survey.extroversion.mean()\n","\n","# Test normality for males\n","male_norm = stats.shapiro(male_survey.extroversion)\n","\n","# Test normality for females\n","female_norm = stats.shapiro(female_survey.extroversion)\n","\n","# Test of equal variance\n","variance_test = stats.levene(male_survey.extroversion,female_survey.extroversion)\n","print(variance_test)"]},{"cell_type":"markdown","id":"5fea025f","metadata":{},"source":["Mental health in tech survey\n","An ongoing 2016 survey aims to measure attitudes towards mental health in the tech workplace, and examine the frequency of mental health conditions among tech workers.\n","\n","You will test if there is an association between willingness to discuss mental health issues with a direct supervisor, discuss_with_supervisor, and if an employee's anonymity will be protected when they take advantage of mental health treatment resources provided by their employer, anonymity_protected.\n","\n","pandas and scipy.stats have been uploaded for you as pd and st, respectively, along with the cleaned survey data as tech_mh."]},{"cell_type":"code","execution_count":null,"id":"d1ed4d1a","metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["# Perform cross tabulation and assign to variable, cross_table\n","cross_table = pd.crosstab(tech_mh.anonymity_protected, tech_mh.discuss_with_supervisor)\n","\n","print(cross_table)"]},{"cell_type":"code","execution_count":null,"id":"89c9ccef","metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["# Conduct the chi-square analysis\n","chi_analysis = st.chi2_contingency(cross_table)\n","\n","print(chi_analysis)"]},{"cell_type":"code","execution_count":null,"id":"9e6ea988","metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["# Perform cross tabulation and assign to variable, cross_table\n","cross_table = pd.crosstab(tech_mh.work_remotely, tech_mh.current_condition)\n","\n","# Conduct chi-square analysis\n","chi_analysis = st.chi2_contingency(cross_table)\n","\n","# Record p-value and expected frequencies\n","p_value = chi_analysis[1]\n","expected_freq = chi_analysis[3]\n","\n","print(p_value)\n","print(expected_freq)"]},{"cell_type":"markdown","id":"15a876d3","metadata":{},"source":["# Dealing with missing data"]},{"cell_type":"markdown","id":"b08dabe5","metadata":{},"source":["# Dealing with missing data\n","It is important to deal with missing data before starting your analysis.\n","\n","One approach is to drop missing values if they account for a small proportion, typically five percent, of your data.\n","\n","Working with a dataset on plane ticket prices, stored as a pandas DataFrame called planes, you'll need to count the number of missing values across all columns, calculate five percent of all values, use this threshold to remove observations, and check how many missing values remain in the dataset."]},{"cell_type":"code","execution_count":null,"id":"2fe0581f","metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["# Count the number of missing values in each column\n","print(planes.isna().sum())\n","\n","# Find the five percent threshold\n","threshold = len(planes) * 0.05\n","\n","# Create a filter\n","cols_to_drop = planes.columns[planes.isna().sum() <= threshold]\n","\n","# Drop missing values for columns below the threshold\n","planes.dropna(subset=cols_to_drop, inplace=True)\n","\n","print(planes.isna().sum())"]},{"cell_type":"markdown","id":"fcada499","metadata":{},"source":["Strategies for remaining missing data\n","The five percent rule has worked nicely for your planes dataset, eliminating missing values from nine out of 11 columns!\n","\n","Now, you need to decide what to do with the \"Additional_Info\" and \"Price\" columns, which are missing 300 and 368 values respectively.\n","\n","You'll first take a look at what \"Additional_Info\" contains, then visualize the price of plane tickets by different airlines.\n","\n","The following imports have been made for you:\n","\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"id":"4712c284","metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["# Check the values of the Additional_Info column\n","print(planes[\"Additional_Info\"].value_counts())\n","\n","# Create a box plot of Price by Airline\n","sns.boxplot(data=planes, x=\"Airline\", y=\"Price\")\n","\n","plt.show()"]},{"cell_type":"markdown","id":"be26dcb9","metadata":{},"source":["Imputing missing plane prices\n","Now there's just one column with missing values left!\n","\n","You've removed the \"Additional_Info\" column from planes—the last step is to impute the missing data in the \"Price\" column of the dataset.\n","\n","As a reminder, you generated this boxplot, which suggested that imputing the median price based on the \"Airline\" is a solid approach!"]},{"cell_type":"code","execution_count":null,"id":"6f71365d","metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["# Calculate median plane ticket prices by Airline\n","airline_prices = planes.groupby(\"Airline\")[\"Price\"].median()\n","\n","print(airline_prices)\n","\n","# Convert to a dictionary\n","prices_dict = airline_prices.to_dict()\n","\n","# Map the dictionary to missing values of Price by Airline\n","planes[\"Price\"] = planes[\"Price\"].fillna(planes[\"Airline\"].map(prices_dict))\n","\n","# Check for missing values\n","print(planes.isna().sum())"]},{"cell_type":"markdown","id":"e1ee0b37","metadata":{},"source":["Finding the number of unique values\n","You would like to practice some of the categorical data manipulation and analysis skills that you've just seen. To help identify which data could be reformatted to extract value, you are going to find out which non-numeric columns in the planes dataset have a large number of unique values.\n","\n","pandas has been imported for you as pd, and the dataset has been stored as planes."]},{"cell_type":"markdown","id":"b345cd29","metadata":{},"source":["Filter planes for columns that are of \"object\" data type.\n","Loop through the columns in the dataset.\n","Add the column iterator to the print statement, then call the function to return the number of unique values in the column."]},{"cell_type":"code","execution_count":null,"id":"5405f8a7","metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["# Filter the DataFrame for object columns\n","non_numeric = planes.select_dtypes(\"object\")\n","\n","# Loop through columns\n","for obj in non_numeric.columns:\n","  \n","  # Print the number of unique values\n","  print(f\"Number of unique values in {obj} column: \", non_numeric[obj].nunique())"]},{"cell_type":"markdown","id":"be278159","metadata":{},"source":["Flight duration categories\n","As you saw, there are 362 unique values in the \"Duration\" column of planes. Calling planes[\"Duration\"].head(), we see the following values:\n","\n","0        19h\n","1     5h 25m\n","2     4h 45m\n","3     2h 25m\n","4    15h 30m\n","Name: Duration, dtype: object\n","Looks like this won't be simple to convert to numbers. However, you could categorize flights by duration and examine the frequency of different flight lengths!\n","\n","You'll create a \"Duration_Category\" column in the planes DataFrame. Before you can do this you'll need to create a list of the values you would like to insert into the DataFrame, followed by the existing values that these should be created from."]},{"cell_type":"code","execution_count":null,"id":"6207b820","metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["# Create a list of categories\n","flight_categories = [\"Short-haul\", \"Medium\", \"Long-haul\"]\n","\n","# Create short-haul values\n","short_flights = \"^0h|^1h|^2h|^3h|^4h\"\n","\n","# Create medium-haul values\n","medium_flights = \"^5h|^6h|^7h|^8h|^9h\"\n","\n","# Create long-haul values\n","long_flights = \"10h|11h|12h|13h|14h|15h|16h\""]},{"cell_type":"markdown","id":"654c1b0f","metadata":{},"source":["Adding duration categories\n","Now that you've set up the categories and values you want to capture, it's time to build a new column to analyze the frequency of flights by duration!\n","\n","The variables flight_categories, short_flights, medium_flights, and long_flights that you previously created are available to you.\n","\n","Additionally, the following packages have been imported: pandas as pd, numpy as np, seaborn as sns, and matplotlib.pyplot as plt."]},{"cell_type":"code","execution_count":null,"id":"cd6054be","metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["# Create conditions for values in flight_categories to be created\n","conditions = [\n","    (planes[\"Duration\"].str.contains(short_flights)),\n","    (planes[\"Duration\"].str.contains(medium_flights)),\n","    (planes[\"Duration\"].str.contains(long_flights))\n","]\n","\n","# Apply the conditions list to the flight_categories\n","planes[\"Duration_Category\"] = np.select(conditions, \n","                                        flight_categories,\n","                                        default=\"Extreme duration\")\n","\n","# Plot the counts of each category\n","sns.countplot(data=planes, x=\"Duration_Category\")\n","plt.show()"]},{"cell_type":"markdown","id":"55771c47","metadata":{},"source":["Flight duration\n","You would like to analyze the duration of flights, but unfortunately, the \"Duration\" column in the planes DataFrame currently contains string values.\n","\n","You'll need to clean the column and convert it to the correct data type for analysis."]},{"cell_type":"code","execution_count":null,"id":"458b8c34","metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["# Preview the column\n","print(planes[\"Duration\"].head())\n","\n","# Remove the string character\n","planes[\"Duration\"] = planes[\"Duration\"].str.replace(\"h\", \"\")\n","\n","# Convert to float data type\n","planes[\"Duration\"] = planes[\"Duration\"].astype(float)\n","\n","# Plot a histogram\n","sns.histplot(data=planes, x=\"Duration\")\n","plt.show()"]},{"cell_type":"markdown","id":"987f74f6","metadata":{},"source":["Adding descriptive statistics\n","Now \"Duration\" and \"Price\" both contain numeric values in the planes DataFrame, you would like to calculate summary statistics for them that are conditional on values in other columns."]},{"cell_type":"markdown","id":"28e335c9","metadata":{},"source":["# Price standard deviation by Airline\n","planes[\"airline_price_st_dev\"] = planes.groupby(\"Airline\")[\"Price\"].transform(lambda x: x.std())\n","\n","print(planes[[\"Airline\", \"airline_price_st_dev\"]].value_counts())"]},{"cell_type":"code","execution_count":null,"id":"babf19d5","metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["# Median Duration by Airline\n","planes[\"airline_median_duration\"] = planes.groupby(\"Airline\")[\"Duration\"].transform(lambda x: x.median())\n","\n","print(planes[[\"Airline\",\"airline_median_duration\"]].value_counts())"]},{"cell_type":"code","execution_count":null,"id":"26507cf6","metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["# Mean Price by Destination\n","planes[\"price_destination_mean\"] = planes.groupby(\"Destination\")[\"Price\"].transform(lambda x: x.mean())\n","\n","print(planes[[\"Destination\",\"price_destination_mean\"]].value_counts())"]},{"cell_type":"markdown","id":"e7b4723d","metadata":{},"source":["Removing outliers\n","While removing outliers isn't always the way to go, for your analysis, you've decided that you will only include flights where the \"Price\" is not an outlier.\n","\n","Therefore, you need to find the upper threshold and then use it to remove values above this from the planes DataFrame.\n","\n","pandas has been imported for you as pd, along with seaborn as sns.\n","\n","Instructions 4/4\n","25 XP\n","Find the 75th and 25th percentiles, saving as price_seventy_fifth and price_twenty_fifth respectively.\n","Calculate the IQR, storing it as prices_iqr.\n","Calculate the upper and lower outlier thresholds.\n","Remove the outliers from planes."]},{"cell_type":"code","execution_count":null,"id":"d610a2c8","metadata":{"vscode":{"languageId":"plaintext"}},"outputs":[],"source":["# Find the 75th and 25th percentiles\n","price_seventy_fifth = planes[\"Price\"].quantile(0.75)\n","price_twenty_fifth = planes[\"Price\"].quantile(0.25)\n","\n","# Calculate iqr\n","prices_iqr = price_seventy_fifth - price_twenty_fifth\n","\n","# Calculate the thresholds\n","upper = price_seventy_fifth + (1.5 * prices_iqr)\n","lower = price_twenty_fifth - (1.5 * prices_iqr)\n","\n","# Subset the data\n","planes = planes[(planes[\"Price\"] > lower) & (planes[\"Price\"] < upper)]\n","\n","print(planes[\"Price\"].describe())"]}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}
